# 决策树法
决策树法主要选用 C4.5 和 CART 来进行计算，并比较其特点和效果。

## 特征提取
决策树在计算的过程中本身就是在对数据的各个特征作各种比较和分析来选取最佳的特征进行划分。
因此在数据处理阶段，我们不必过于关注应该选用那些特征、放弃哪些特征。因为这是在决策树算法的过程中也会考虑的问题。
事先去除一些不佳的特征实际上对结果不会有太大影响。

不过，去除特征可以在效率上得到很大的提升。或者通过控制 max_feature 参数来控制建成决策树的速度。max_feature 表示用于决策的最大特征数。

但是，本部分只考虑单一决策树的情况，除非是在大规模调参的情境下，否则在所给的数据集下，即使不进行特征提取也具有很高的效率。

## 预处理数据
由于使用决策树法，不需要对数据进行归一化。

对于标记值。如数据中的 `career_o`。其用 1,2,3 等值来表示不同的职业，如果不作相应的处理，则会被视作具有偏序关系的标量。处理的方法之一是进行向量化。即`vectorizer`。

对于字符串值也可以使用类似的方法。不过，遗憾的是，该数据集中的字符串特征均为取值多、频数少的值，取值可达数百种之多。可以预料到，其并不适合作为决策树分类用的特征。

## 离散化
C4.5 和 CART 都有处理连续数据的能力，因此不需要离散化。

## 缺失值补全
缺失值。这里的缺失值基本全部出现在作为标量值的特征中，因此将缺失值设-1未必可取，反而可能干扰到决策树的划分。可以考虑用平均值或者众数来代替。

本项目使用众数作为处理缺失值的方法。

## 模型选择
### C4.5 (entropy)

基于信息熵进行决策。

sklearn 中没有裸的 C4.5，
但是可以将 DecisionTreeClassifier 的 `criterion` 参数 设为 `entropy` 来得到一个经优化的 C4.5 决策树。

通过交叉验证计算准确率的方法，暴力枚举大量参数，启用向量化，使用特征选择来加速，选择最优的超参数。

经过调参，当树深度 = 7，使用最优随机划分，最小叶子节点为 8 时，交叉验证得到最好的训练准确率 85.30%，相应的测试准确率为 82.17%。

在上述参数下，标记数据向量化和特征选择对交叉验证效果的影响。

|            | 向量化 | 无向量化 |
| ---------- | ------ | -------- |
| 特征选择   | 85.30% | 84.69%   |
| 无特征选择 | 84.78% | 84.45%   |

由于在寻找最优参数的时候是启用了向量化和特征选择的，因此上表的差异在意料之中。
两者的差距不到 0.9%，准确率的值较为稳定。因此无法断定特征选择和向量化在该数据集上是有效的（单决策树）。

## CART (gini)

同样的，sklearn 的 `criterion` 参数 设为 `gini` 来得到一个经优化的 CART 决策树。

经过调参，当树深度 = 7，使用最优随机划分，最小叶子节点为 4，最小分割数为 16 时，交叉验证得到最好的训练准确率 85.23%，相应的测试准确率为 85.14%。

但是，测试集的数据量非常小，该测试准确率具有一定的偶然性，不能断言 CART 在该问题上会优于 C4.5。我们需要考量更多的信息。

|            | 向量化 | 无向量化 |
| ---------- | ------ | -------- |
| 特征选择   | 85.23% | 84.57%   |
| 无特征选择 | 84.48% | 83.70%   |

由于在寻找最优参数的时候是启用了向量化和特征选择的，因此上表的差异在意料之中。
两者的差距不到 1.53%，准确率的值较为稳定。因此无法断定特征选择和向量化在该数据集上是有效的（单决策树）。该结果略差于 C4.5。

对于 CART 和 C4.5，树深限制的影响如下：

| max length                     | 5      | 6      | 7      | 8      | 9      |
| ------------------------------ | ------ | ------ | ------ | ------ | ------ |
| CART Cross Validation Accuracy | 84.46% | 84.43% | 85.23% | 84.10% | 84.01% |
| C4.5 Cross Validation Accuracy | 84.81% | 85.47% | 85.30% | 84.34% | 84.53% |

可见，在该问题下，C4.5 的准确率更加稳定，更不容易出现过拟合和欠拟合的情况。

可以通过生成的决策树来对比两者的区别：