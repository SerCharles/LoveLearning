# 决策树法
决策树法主要选用 C4.5 和 CART 来进行计算，并比较其特点和效果。

## 特征提取
决策树在计算的过程中本身就是在对数据的各个特征作各种比较和分析来选取最佳的特征进行划分。
因此在数据处理阶段，我们不必过于关注应该选用那些特征、放弃哪些特征。因为这是在决策树算法的过程中也会考虑的问题。
事先去除一些不佳的特征实际上对结果不会有太大影响。

不过，去除特征可以在效率上得到很大的提升。或者通过控制 max_feature 参数来控制建成决策树的速度。max_feature 表示用于决策的最大特征数。

但是，本部分只考虑单一决策树的情况，除非是在大规模调参的情境下，否则在所给的数据集下，即使不进行特征提取也具有很高的效率。

实际测试的结果表明，对于单一决策树，在控制参数使其不发生过拟合的情况下，特征提取对准确率无明显影响。

## 预处理数据
由于使用决策树法，不需要对数据进行归一化。

对于标记值。如数据中的 `career_o`。其用 1,2,3 等值来表示不同的职业，如果不作相应的处理，则会被视作具有偏序关系的标量。处理的方法之一是进行向量化。即`vectorizer`。

对于字符串值也可以使用类似的方法。不过，遗憾的是，该数据集中的字符串特征均为取值多、频数少的值，取值可达数百种之多。可以预料到，其并不适合作为决策树分类用的特征。

## 离散化
C4.5 和 CART 都有处理连续数据的能力，因此不需要离散化。

## 缺失值补全
缺失值。这里的缺失值基本全部出现在作为标量值的特征中，因此将缺失值设-1未必可取，反而可能干扰到决策树的划分。可以考虑用平均值或者众数来代替。

本项目使用众数作为处理缺失值的方法。
